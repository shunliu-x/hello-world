{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "欢迎使用 Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shunliu-x/hello-world/blob/master/%E6%AC%A2%E8%BF%8E%E4%BD%BF%E7%94%A8_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"45px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1>欢迎使用 Colaboratory！</h1>\n",
        "\n",
        "\n",
        "Colaboratory 是一个免费的 Jupyter 笔记本环境，不需要进行任何设置就可以使用，并且完全在云端运行。\n",
        "\n",
        "借助 Colaboratory，您可以编写和执行代码、保存和共享分析结果，以及利用强大的计算资源，所有这些都可通过浏览器免费使用。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xitplqMNk_Hc",
        "outputId": "ed4f60d2-878d-4056-c438-352dac39a112",
        "colab": {
          "height": 420
        }
      },
      "source": [
        "#@title Colaboratory 简介 { display-mode: \"form\" }\n",
        "#@markdown 下面这个时长 3 分钟的视频概述了 Colaboratory 的主要功能：\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('inN8seMm7UI', width=600, height=400)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"600\"\n",
              "            height=\"400\"\n",
              "            src=\"https://www.youtube.com/embed/inN8seMm7UI\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7f956e9dda50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GJBs_flRovLc"
      },
      "source": [
        "## 使用入门\n",
        "\n",
        "您正在阅读的文档是托管在 Colaboratory 中的 <a href=\"https://jupyter.org/\">Jupyter 笔记本</a>。它并非静态页面，而是一个可让您以 Python 和其他语言编写和执行代码的互动环境。\n",
        "\n",
        "例如，以下<strong>代码单元格</strong>包含一个简短的 Python 脚本，该脚本会计算值、将其存储在变量中并输出结果："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gJr_9dXGpJ05",
        "outputId": "5626194c-e802-4293-942d-2908885c3c1f",
        "colab": {
          "height": 35
        }
      },
      "source": [
        "seconds_in_a_day = 24 * 60 * 60\n",
        "seconds_in_a_day"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "要执行上述单元格中的代码，请点击选择它，然后按代码左侧的“播放”按钮，或使用键盘快捷键“Command/Ctrl+Enter”。\n",
        "\n",
        "所有单元格都会修改同一全局状态，因此您通过执行某个单元格定义的变量可用在其他单元格中："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-gE-Ez1qtyIA",
        "outputId": "8d2e4259-4682-4e19-b683-7b9087f28820",
        "colab": {
          "height": 35
        }
      },
      "source": [
        "seconds_in_a_week = 7 * seconds_in_a_day\n",
        "seconds_in_a_week"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "604800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lSrWNr3MuFUS"
      },
      "source": [
        "要详细了解如何使用 Colaboratory 笔记本，请参阅 <a href=\"/notebooks/basic_features_overview.ipynb\">Colaboratory 概览</a>。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Rh3-Vt9Nev9"
      },
      "source": [
        "## 更多资源\n",
        "\n",
        "要了解如何充分利用 Python、Jupyter、Colaboratory 和相关工具，请参阅以下资源：\n",
        "\n",
        "### 在 Colaboratory 中使用笔记本\n",
        "- [Colaboratory 概览](/notebooks/basic_features_overview.ipynb)\n",
        "- [Markdown 指南](/notebooks/markdown_guide.ipynb)\n",
        "- [导入库和安装依赖项](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [在 GitHub 中保存和加载笔记本](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
        "- [互动表单](/notebooks/forms.ipynb)\n",
        "- [互动微件](/notebooks/widgets.ipynb)\n",
        "\n",
        "### 处理数据\n",
        "- [加载数据：云端硬盘、表格和 Google Cloud Storage](/notebooks/io.ipynb) \n",
        "- [图表：可视化数据](/notebooks/charts.ipynb)\n",
        "- [BigQuery 使用入门](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### 机器学习速成课程\n",
        "以下是可以在 Google 的在线机器学习课程中找到的部分笔记本。请查看<a href=\"https://developers.google.com/machine-learning/crash-course/\">完整课程网站</a>了解详情。\n",
        "- [Pandas 简介](/notebooks/mlcc/intro_to_pandas.ipynb)\n",
        "- [Tensorflow 概念](/notebooks/mlcc/tensorflow_programming_concepts.ipynb)\n",
        "- [使用 TensorFlow 的起始步骤](/notebooks/mlcc/first_steps_with_tensor_flow.ipynb)\n",
        "- [神经网络简介](/notebooks/mlcc/intro_to_neural_nets.ipynb)\n",
        "- [稀疏数据和嵌入简介](/notebooks/mlcc/intro_to_sparse_data_and_embeddings.ipynb)\n",
        "\n",
        "### 使用加速硬件\n",
        "- [将 TensorFlow 与 GPU 配合使用](/notebooks/gpu.ipynb)\n",
        "- [将 TensorFlow 与 TPU 配合使用](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zh4JELwK-WyB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "74a4e147-6b73-45f6-fae4-a4abf80834fe"
      },
      "source": [
        "! unrar x test.rar"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from test.rar\n",
            "\n",
            "Creating    test                                                      OK\n",
            "Extracting  test/11.jpg                                                  \b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  test/12.jpg                                                  \b\b\b\b 11%\b\b\b\b\b  OK \n",
            "Extracting  test/13.jpg                                                  \b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  test/21.jpg                                                  \b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  test/31.jpg                                                  \b\b\b\b 52%\b\b\b\b 57%\b\b\b\b\b  OK \n",
            "Extracting  test/32.jpg                                                  \b\b\b\b 59%\b\b\b\b\b  OK \n",
            "Extracting  test/33.jpg                                                  \b\b\b\b 77%\b\b\b\b\b  OK \n",
            "Extracting  test/41.jpg                                                  \b\b\b\b 88%\b\b\b\b\b  OK \n",
            "Extracting  test/42.jpg                                                  \b\b\b\b 90%\b\b\b\b\b  OK \n",
            "Extracting  test/43.jpg                                                  \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux4TP7sj_Cxj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "25de577e-3604-40b7-be0a-f77fde7aef22"
      },
      "source": [
        "! unrar x data.rar"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from data.rar\n",
            "\n",
            "Creating    data                                                      OK\n",
            "Extracting  data/1001.jpg                                                \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  data/1002.jpg                                                \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  data/1003.jpg                                                \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  data/1004.jpg                                                \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  data/1005.jpg                                                \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  data/1006.jpg                                                \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  data/1007.jpg                                                \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  data/1008.jpg                                                \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  data/1009.jpg                                                \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  data/1010.jpg                                                \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  data/1011.jpg                                                \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  data/1012.jpg                                                \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  data/1013.jpg                                                \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  data/1014.jpg                                                \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  data/1015.jpg                                                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  data/1016.jpg                                                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  data/1017.jpg                                                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  data/1018.jpg                                                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  data/1019.jpg                                                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  data/1020.jpg                                                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  data/1021.jpg                                                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  data/1022.jpg                                                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  data/1023.jpg                                                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  data/1024.jpg                                                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  data/1025.jpg                                                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  data/1026.jpg                                                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  data/1027.jpg                                                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  data/1028.jpg                                                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  data/1029.jpg                                                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  data/1030.jpg                                                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  data/1031.jpg                                                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  data/1032.jpg                                                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  data/1033.jpg                                                \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  data/1034.jpg                                                \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  data/1035.jpg                                                \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  data/1036.jpg                                                \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  data/1037.jpg                                                \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  data/1038.jpg                                                \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  data/1039.jpg                                                \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  data/1040.jpg                                                \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  data/1041.jpg                                                \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  data/1042.jpg                                                \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  data/1043.jpg                                                \b\b\b\b  2%\b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b 16%\b\b\b\b\b  OK \n",
            "Extracting  data/1044.jpg                                                \b\b\b\b 16%\b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 30%\b\b\b\b\b  OK \n",
            "Extracting  data/1045.jpg                                                \b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 33%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b\b  OK \n",
            "Extracting  data/1046.jpg                                                \b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b 48%\b\b\b\b\b  OK \n",
            "Extracting  data/1047.jpg                                                \b\b\b\b 48%\b\b\b\b 49%\b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b\b  OK \n",
            "Extracting  data/1048.jpg                                                \b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b 64%\b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  data/1049.jpg                                                \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  data/1050.jpg                                                \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  data/1051.jpg                                                \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  data/1052.jpg                                                \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  data/1053.jpg                                                \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  data/1054.jpg                                                \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  data/1055.jpg                                                \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  data/1056.jpg                                                \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  data/1057.jpg                                                \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  data/1058.jpg                                                \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  data/1059.jpg                                                \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  data/1060.jpg                                                \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  data/1061.jpg                                                \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  data/1062.jpg                                                \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  data/1063.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1064.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1065.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1066.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1067.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1068.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1069.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1070.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1071.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1072.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1073.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1074.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1075.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1076.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1077.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1078.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1079.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1080.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1081.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1082.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1083.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1084.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1085.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1086.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1087.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1088.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1089.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1090.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1091.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1092.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1093.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1094.jpg                                                \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  data/1095.jpg                                                \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  data/1096.jpg                                                \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  data/1097.jpg                                                \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  data/1098.jpg                                                \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  data/1099.jpg                                                \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  data/1100.jpg                                                \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  data/2001.jpg                                                \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  data/2002.jpg                                                \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  data/2003.jpg                                                \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  data/2004.jpg                                                \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  data/2005.jpg                                                \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  data/2006.jpg                                                \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  data/2007.jpg                                                \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  data/2008.jpg                                                \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  data/2009.jpg                                                \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  data/2010.jpg                                                \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  data/2011.jpg                                                \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  data/2012.jpg                                                \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  data/2013.jpg                                                \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  data/2014.jpg                                                \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  data/2015.jpg                                                \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  data/2016.jpg                                                \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  data/2017.jpg                                                \b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  data/2018.jpg                                                \b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  data/2019.jpg                                                \b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  data/2020.jpg                                                \b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  data/2021.jpg                                                \b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  data/2022.jpg                                                \b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  data/2023.jpg                                                \b\b\b\b 70%\b\b\b\b\b  OK \n",
            "Extracting  data/2024.jpg                                                \b\b\b\b 70%\b\b\b\b\b  OK \n",
            "Extracting  data/2025.jpg                                                \b\b\b\b 70%\b\b\b\b\b  OK \n",
            "Extracting  data/2026.jpg                                                \b\b\b\b 70%\b\b\b\b\b  OK \n",
            "Extracting  data/2027.jpg                                                \b\b\b\b 70%\b\b\b\b\b  OK \n",
            "Extracting  data/2028.jpg                                                \b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  data/2029.jpg                                                \b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  data/2030.jpg                                                \b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  data/2031.jpg                                                \b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  data/2032.jpg                                                \b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  data/2033.jpg                                                \b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  data/2034.jpg                                                \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  data/2035.jpg                                                \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  data/2036.jpg                                                \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  data/2037.jpg                                                \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  data/2038.jpg                                                \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  data/2039.jpg                                                \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  data/2040.jpg                                                \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  data/2041.jpg                                                \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  data/2042.jpg                                                \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  data/2043.jpg                                                \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  data/2044.jpg                                                \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  data/2045.jpg                                                \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  data/2046.jpg                                                \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  data/2047.jpg                                                \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  data/2048.jpg                                                \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  data/2049.jpg                                                \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  data/2050.jpg                                                \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  data/2051.jpg                                                \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  data/2052.jpg                                                \b\b\b\b 73%\b\b\b\b 74%\b\b\b\b\b  OK \n",
            "Extracting  data/2053.jpg                                                \b\b\b\b 74%\b\b\b\b\b  OK \n",
            "Extracting  data/2054.jpg                                                \b\b\b\b 74%\b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  data/2055.jpg                                                \b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  data/2056.jpg                                                \b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  data/2057.jpg                                                \b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  data/2058.jpg                                                \b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  data/2059.jpg                                                \b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  data/2060.jpg                                                \b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  data/2061.jpg                                                \b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  data/2062.jpg                                                \b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  data/2063.jpg                                                \b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  data/2064.jpg                                                \b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  data/2065.jpg                                                \b\b\b\b 76%\b\b\b\b\b  OK \n",
            "Extracting  data/2066.jpg                                                \b\b\b\b 76%\b\b\b\b\b  OK \n",
            "Extracting  data/2067.jpg                                                \b\b\b\b 76%\b\b\b\b\b  OK \n",
            "Extracting  data/2068.jpg                                                \b\b\b\b 76%\b\b\b\b\b  OK \n",
            "Extracting  data/2069.jpg                                                \b\b\b\b 77%\b\b\b\b\b  OK \n",
            "Extracting  data/2070.jpg                                                \b\b\b\b 77%\b\b\b\b\b  OK \n",
            "Extracting  data/2071.jpg                                                \b\b\b\b 77%\b\b\b\b\b  OK \n",
            "Extracting  data/2072.jpg                                                \b\b\b\b 77%\b\b\b\b\b  OK \n",
            "Extracting  data/2073.jpg                                                \b\b\b\b 77%\b\b\b\b\b  OK \n",
            "Extracting  data/2074.jpg                                                \b\b\b\b 77%\b\b\b\b\b  OK \n",
            "Extracting  data/2075.jpg                                                \b\b\b\b 77%\b\b\b\b\b  OK \n",
            "Extracting  data/2076.jpg                                                \b\b\b\b 77%\b\b\b\b\b  OK \n",
            "Extracting  data/2077.jpg                                                \b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  data/2078.jpg                                                \b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  data/2079.jpg                                                \b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  data/2080.jpg                                                \b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  data/2081.jpg                                                \b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  data/2082.jpg                                                \b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  data/2083.jpg                                                \b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  data/2084.jpg                                                \b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  data/2085.jpg                                                \b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  data/2086.jpg                                                \b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  data/2087.jpg                                                \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  data/2088.jpg                                                \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  data/2089.jpg                                                \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  data/2090.jpg                                                \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  data/2091.jpg                                                \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  data/2092.jpg                                                \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  data/2093.jpg                                                \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  data/2094.jpg                                                \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  data/2095.jpg                                                \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  data/2096.jpg                                                \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  data/2097.jpg                                                \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  data/2098.jpg                                                \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  data/2099.jpg                                                \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  data/2100.jpg                                                \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  data/3001.jpg                                                \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  data/3002.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3003.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3004.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3005.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3006.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3007.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3008.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3009.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3010.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3011.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3012.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3013.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3014.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3015.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3016.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3017.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3018.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3019.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3020.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3021.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3022.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3023.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3024.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3025.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3026.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3027.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3028.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3029.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3030.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3031.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3032.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3033.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3034.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3035.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3036.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3037.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3038.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3039.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3040.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3041.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3042.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3043.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3044.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3045.jpg                                                \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  data/3046.jpg                                                \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  data/3047.jpg                                                \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  data/3048.jpg                                                \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  data/3049.jpg                                                \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  data/3050.jpg                                                \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  data/3051.jpg                                                \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  data/3052.jpg                                                \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  data/3053.jpg                                                \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  data/3054.jpg                                                \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  data/3055.jpg                                                \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  data/3056.jpg                                                \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  data/3057.jpg                                                \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  data/3058.jpg                                                \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  data/3059.jpg                                                \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  data/3060.jpg                                                \b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  data/3061.jpg                                                \b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  data/3062.jpg                                                \b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  data/3063.jpg                                                \b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  data/3064.jpg                                                \b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  data/3065.jpg                                                \b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  data/3066.jpg                                                \b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  data/3067.jpg                                                \b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  data/3068.jpg                                                \b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  data/3069.jpg                                                \b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  data/3070.jpg                                                \b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  data/3071.jpg                                                \b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  data/3072.jpg                                                \b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  data/3073.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3074.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3075.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3076.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3077.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3078.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3079.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3080.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3081.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3082.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3083.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3084.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3085.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3086.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3087.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3088.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3089.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3090.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3091.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3092.jpg                                                \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  data/3093.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3094.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3095.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3096.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3097.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3098.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3099.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3100.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3101.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3102.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3103.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3104.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3105.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3106.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3107.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3108.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3109.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3110.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3111.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3112.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3113.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3114.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3115.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3116.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3117.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3118.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3119.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/3120.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/4001.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/4002.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/4003.jpg                                                \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  data/4004.jpg                                                \b\b\b\b 85%\b\b\b\b\b  OK \n",
            "Extracting  data/4005.jpg                                                \b\b\b\b 85%\b\b\b\b 86%\b\b\b\b\b  OK \n",
            "Extracting  data/4006.jpg                                                \b\b\b\b 87%\b\b\b\b\b  OK \n",
            "Extracting  data/4007.jpg                                                \b\b\b\b 87%\b\b\b\b\b  OK \n",
            "Extracting  data/4008.jpg                                                \b\b\b\b 87%\b\b\b\b\b  OK \n",
            "Extracting  data/4009.jpg                                                \b\b\b\b 87%\b\b\b\b\b  OK \n",
            "Extracting  data/4010.jpg                                                \b\b\b\b 87%\b\b\b\b\b  OK \n",
            "Extracting  data/4011.jpg                                                \b\b\b\b 87%\b\b\b\b\b  OK \n",
            "Extracting  data/4012.jpg                                                \b\b\b\b 88%\b\b\b\b\b  OK \n",
            "Extracting  data/4013.jpg                                                \b\b\b\b 88%\b\b\b\b\b  OK \n",
            "Extracting  data/4014.jpg                                                \b\b\b\b 88%\b\b\b\b\b  OK \n",
            "Extracting  data/4015.jpg                                                \b\b\b\b 88%\b\b\b\b\b  OK \n",
            "Extracting  data/4016.jpg                                                \b\b\b\b 88%\b\b\b\b 89%\b\b\b\b\b  OK \n",
            "Extracting  data/4017.jpg                                                \b\b\b\b 89%\b\b\b\b\b  OK \n",
            "Extracting  data/4018.jpg                                                \b\b\b\b 90%\b\b\b\b\b  OK \n",
            "Extracting  data/4019.jpg                                                \b\b\b\b 90%\b\b\b\b\b  OK \n",
            "Extracting  data/4020.jpg                                                \b\b\b\b 90%\b\b\b\b\b  OK \n",
            "Extracting  data/4021.jpg                                                \b\b\b\b 90%\b\b\b\b\b  OK \n",
            "Extracting  data/4022.jpg                                                \b\b\b\b 90%\b\b\b\b\b  OK \n",
            "Extracting  data/4023.jpg                                                \b\b\b\b 90%\b\b\b\b\b  OK \n",
            "Extracting  data/4024.jpg                                                \b\b\b\b 91%\b\b\b\b\b  OK \n",
            "Extracting  data/4025.jpg                                                \b\b\b\b 91%\b\b\b\b\b  OK \n",
            "Extracting  data/4026.jpg                                                \b\b\b\b 91%\b\b\b\b\b  OK \n",
            "Extracting  data/4027.jpg                                                \b\b\b\b 91%\b\b\b\b\b  OK \n",
            "Extracting  data/4028.jpg                                                \b\b\b\b 91%\b\b\b\b\b  OK \n",
            "Extracting  data/4029.jpg                                                \b\b\b\b 91%\b\b\b\b\b  OK \n",
            "Extracting  data/4030.jpg                                                \b\b\b\b 91%\b\b\b\b\b  OK \n",
            "Extracting  data/4031.jpg                                                \b\b\b\b 92%\b\b\b\b\b  OK \n",
            "Extracting  data/4032.jpg                                                \b\b\b\b 92%\b\b\b\b\b  OK \n",
            "Extracting  data/4033.jpg                                                \b\b\b\b 92%\b\b\b\b\b  OK \n",
            "Extracting  data/4034.jpg                                                \b\b\b\b 92%\b\b\b\b\b  OK \n",
            "Extracting  data/4035.jpg                                                \b\b\b\b 92%\b\b\b\b\b  OK \n",
            "Extracting  data/4036.jpg                                                \b\b\b\b 92%\b\b\b\b\b  OK \n",
            "Extracting  data/4037.jpg                                                \b\b\b\b 93%\b\b\b\b\b  OK \n",
            "Extracting  data/4038.jpg                                                \b\b\b\b 93%\b\b\b\b\b  OK \n",
            "Extracting  data/4039.jpg                                                \b\b\b\b 93%\b\b\b\b\b  OK \n",
            "Extracting  data/4040.jpg                                                \b\b\b\b 93%\b\b\b\b\b  OK \n",
            "Extracting  data/4041.jpg                                                \b\b\b\b 93%\b\b\b\b\b  OK \n",
            "Extracting  data/4042.jpg                                                \b\b\b\b 93%\b\b\b\b\b  OK \n",
            "Extracting  data/4043.jpg                                                \b\b\b\b 93%\b\b\b\b\b  OK \n",
            "Extracting  data/4044.jpg                                                \b\b\b\b 93%\b\b\b\b\b  OK \n",
            "Extracting  data/4045.jpg                                                \b\b\b\b 93%\b\b\b\b\b  OK \n",
            "Extracting  data/4046.jpg                                                \b\b\b\b 93%\b\b\b\b\b  OK \n",
            "Extracting  data/4047.jpg                                                \b\b\b\b 93%\b\b\b\b\b  OK \n",
            "Extracting  data/4048.jpg                                                \b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  data/4049.jpg                                                \b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  data/4050.jpg                                                \b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  data/4051.jpg                                                \b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  data/4052.jpg                                                \b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  data/4053.jpg                                                \b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  data/4054.jpg                                                \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  data/4055.jpg                                                \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  data/4056.jpg                                                \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  data/4057.jpg                                                \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  data/4058.jpg                                                \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  data/4059.jpg                                                \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  data/4060.jpg                                                \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  data/4061.jpg                                                \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  data/4062.jpg                                                \b\b\b\b 96%\b\b\b\b\b  OK \n",
            "Extracting  data/4063.jpg                                                \b\b\b\b 96%\b\b\b\b\b  OK \n",
            "Extracting  data/4064.jpg                                                \b\b\b\b 96%\b\b\b\b\b  OK \n",
            "Extracting  data/4065.jpg                                                \b\b\b\b 96%\b\b\b\b\b  OK \n",
            "Extracting  data/4066.jpg                                                \b\b\b\b 96%\b\b\b\b\b  OK \n",
            "Extracting  data/4067.jpg                                                \b\b\b\b 96%\b\b\b\b\b  OK \n",
            "Extracting  data/4068.jpg                                                \b\b\b\b 96%\b\b\b\b\b  OK \n",
            "Extracting  data/4069.jpg                                                \b\b\b\b 96%\b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  data/4070.jpg                                                \b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  data/4071.jpg                                                \b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  data/4072.jpg                                                \b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  data/4073.jpg                                                \b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  data/4074.jpg                                                \b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  data/4075.jpg                                                \b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  data/4076.jpg                                                \b\b\b\b 98%\b\b\b\b\b  OK \n",
            "Extracting  data/4077.jpg                                                \b\b\b\b 98%\b\b\b\b\b  OK \n",
            "Extracting  data/4078.jpg                                                \b\b\b\b 98%\b\b\b\b\b  OK \n",
            "Extracting  data/4079.jpg                                                \b\b\b\b 98%\b\b\b\b\b  OK \n",
            "Extracting  data/4080.jpg                                                \b\b\b\b 98%\b\b\b\b\b  OK \n",
            "Extracting  data/4081.jpg                                                \b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  data/4082.jpg                                                \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  data/4083.jpg                                                \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  data/4084.jpg                                                \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  data/4085.jpg                                                \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  data/4086.jpg                                                \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  data/4087.jpg                                                \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  data/4088.jpg                                                \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  data/4089.jpg                                                \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  data/4090.jpg                                                \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  data/4091.jpg                                                \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  data/4092.jpg                                                \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z2t9_ek_Kjm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "709a8c1e-dbc7-48cd-9edc-07c3088edc85"
      },
      "source": [
        "! python train.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "1\n",
            "WARNING:tensorflow:From train.py:14: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/inception_resnet_v2.py:241: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "Tensor(\"InceptionResnetV2/Logits/Logits/BiasAdd:0\", shape=(?, 200), dtype=float32)\n",
            "WARNING:tensorflow:From train.py:20: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:21: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:22: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:25: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-09-11 06:32:13.555157: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-09-11 06:32:13.604538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-11 06:32:13.605324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-11 06:32:13.615984: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-11 06:32:13.797116: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-11 06:32:13.893470: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-11 06:32:13.916200: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-11 06:32:14.120756: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-11 06:32:14.234185: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-11 06:32:14.590728: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-11 06:32:14.591031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-11 06:32:14.591883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-11 06:32:14.592564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-11 06:32:14.615249: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-09-11 06:32:14.617085: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2a932c0 executing computations on platform Host. Devices:\n",
            "2019-09-11 06:32:14.617121: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-09-11 06:32:14.715776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-11 06:32:14.716656: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2a93480 executing computations on platform CUDA. Devices:\n",
            "2019-09-11 06:32:14.716694: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-09-11 06:32:14.717926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-11 06:32:14.718606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-11 06:32:14.718725: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-11 06:32:14.718774: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-11 06:32:14.718807: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-11 06:32:14.718838: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-11 06:32:14.718865: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-11 06:32:14.718895: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-11 06:32:14.718927: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-11 06:32:14.719024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-11 06:32:14.719803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-11 06:32:14.720448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-11 06:32:14.723762: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-11 06:32:14.725391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-09-11 06:32:14.725427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-09-11 06:32:14.725443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-09-11 06:32:14.727369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-11 06:32:14.728155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-11 06:32:14.728854: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-09-11 06:32:14.728907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /content/data.py:47: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /content/data.py:48: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
            "WARNING:tensorflow:From /content/data.py:50: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/data.py:51: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/data.py:60: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n",
            "2019-09-11 06:32:18.859205: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "WARNING:tensorflow:From train.py:29: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "2019-09-11 06:32:28.969198: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-11 06:32:29.780309: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "global_step is: 11 the epoch is  0 the num is: 10 the loss is : 1.4637078 the accuracy is : 0.3125 the learning_rate is : 0.1\n",
            "global_step is: 21 the epoch is  0 the num is: 20 the loss is : 1.4096885 the accuracy is : 0.328125 the learning_rate is : 0.1\n",
            "global_step is: 31 the epoch is  0 the num is: 30 the loss is : 1.3769019 the accuracy is : 0.3125 the learning_rate is : 0.1\n",
            "global_step is: 41 the epoch is  0 the num is: 40 the loss is : 1.4267888 the accuracy is : 0.328125 the learning_rate is : 0.1\n",
            "global_step is: 51 the epoch is  0 the num is: 50 the loss is : 1.316303 the accuracy is : 0.40625 the learning_rate is : 0.1\n",
            "global_step is: 61 the epoch is  0 the num is: 60 the loss is : 1.1666039 the accuracy is : 0.421875 the learning_rate is : 0.1\n",
            "global_step is: 71 the epoch is  0 the num is: 70 the loss is : 1.0519762 the accuracy is : 0.53125 the learning_rate is : 0.1\n",
            "global_step is: 81 the epoch is  0 the num is: 80 the loss is : 1.2621571 the accuracy is : 0.40625 the learning_rate is : 0.1\n",
            "global_step is: 91 the epoch is  0 the num is: 90 the loss is : 1.213011 the accuracy is : 0.5625 the learning_rate is : 0.1\n",
            "global_step is: 101 the epoch is  0 the num is: 100 the loss is : 1.0152743 the accuracy is : 0.59375 the learning_rate is : 0.1\n",
            "global_step is: 111 the epoch is  0 the num is: 110 the loss is : 0.9304769 the accuracy is : 0.5 the learning_rate is : 0.1\n",
            "global_step is: 121 the epoch is  0 the num is: 120 the loss is : 1.2301517 the accuracy is : 0.5625 the learning_rate is : 0.1\n",
            "global_step is: 131 the epoch is  0 the num is: 130 the loss is : 0.9024896 the accuracy is : 0.625 the learning_rate is : 0.1\n",
            "global_step is: 141 the epoch is  0 the num is: 140 the loss is : 0.95001787 the accuracy is : 0.59375 the learning_rate is : 0.1\n",
            "global_step is: 151 the epoch is  0 the num is: 150 the loss is : 0.8915193 the accuracy is : 0.5625 the learning_rate is : 0.1\n",
            "global_step is: 161 the epoch is  0 the num is: 160 the loss is : 1.1346679 the accuracy is : 0.453125 the learning_rate is : 0.1\n",
            "global_step is: 171 the epoch is  0 the num is: 170 the loss is : 1.4053006 the accuracy is : 0.4375 the learning_rate is : 0.1\n",
            "global_step is: 181 the epoch is  0 the num is: 180 the loss is : 1.1726542 the accuracy is : 0.4375 the learning_rate is : 0.1\n",
            "global_step is: 191 the epoch is  0 the num is: 190 the loss is : 1.7761266 the accuracy is : 0.328125 the learning_rate is : 0.1\n",
            "global_step is: 201 the epoch is  0 the num is: 200 the loss is : 1.1636584 the accuracy is : 0.5625 the learning_rate is : 0.1\n",
            "global_step is: 211 the epoch is  0 the num is: 210 the loss is : 1.1115907 the accuracy is : 0.515625 the learning_rate is : 0.1\n",
            "global_step is: 221 the epoch is  0 the num is: 220 the loss is : 0.6456688 the accuracy is : 0.8125 the learning_rate is : 0.1\n",
            "global_step is: 231 the epoch is  0 the num is: 230 the loss is : 0.96282136 the accuracy is : 0.515625 the learning_rate is : 0.1\n",
            "global_step is: 241 the epoch is  0 the num is: 240 the loss is : 0.8738085 the accuracy is : 0.609375 the learning_rate is : 0.1\n",
            "global_step is: 251 the epoch is  0 the num is: 250 the loss is : 1.0441033 the accuracy is : 0.5625 the learning_rate is : 0.1\n",
            "global_step is: 261 the epoch is  0 the num is: 260 the loss is : 0.8124995 the accuracy is : 0.640625 the learning_rate is : 0.1\n",
            "global_step is: 271 the epoch is  0 the num is: 270 the loss is : 0.59156585 the accuracy is : 0.75 the learning_rate is : 0.1\n",
            "global_step is: 281 the epoch is  0 the num is: 280 the loss is : 0.857134 the accuracy is : 0.6875 the learning_rate is : 0.1\n",
            "global_step is: 291 the epoch is  0 the num is: 290 the loss is : 0.53086925 the accuracy is : 0.734375 the learning_rate is : 0.1\n",
            "global_step is: 301 the epoch is  0 the num is: 300 the loss is : 0.89483845 the accuracy is : 0.5625 the learning_rate is : 0.094000004\n",
            "global_step is: 311 the epoch is  0 the num is: 310 the loss is : 0.52067864 the accuracy is : 0.71875 the learning_rate is : 0.094000004\n",
            "global_step is: 321 the epoch is  0 the num is: 320 the loss is : 12.075919 the accuracy is : 0.421875 the learning_rate is : 0.094000004\n",
            "global_step is: 331 the epoch is  0 the num is: 330 the loss is : 1.1705201 the accuracy is : 0.4375 the learning_rate is : 0.094000004\n",
            "global_step is: 341 the epoch is  0 the num is: 340 the loss is : 1.1694611 the accuracy is : 0.375 the learning_rate is : 0.094000004\n",
            "global_step is: 351 the epoch is  0 the num is: 350 the loss is : 1.0345447 the accuracy is : 0.546875 the learning_rate is : 0.094000004\n",
            "global_step is: 361 the epoch is  0 the num is: 360 the loss is : 0.97531605 the accuracy is : 0.515625 the learning_rate is : 0.094000004\n",
            "global_step is: 371 the epoch is  0 the num is: 370 the loss is : 1.0472453 the accuracy is : 0.578125 the learning_rate is : 0.094000004\n",
            "global_step is: 381 the epoch is  0 the num is: 380 the loss is : 0.91347873 the accuracy is : 0.6875 the learning_rate is : 0.094000004\n",
            "global_step is: 391 the epoch is  0 the num is: 390 the loss is : 0.87930113 the accuracy is : 0.671875 the learning_rate is : 0.094000004\n",
            "global_step is: 401 the epoch is  0 the num is: 400 the loss is : 0.93847525 the accuracy is : 0.53125 the learning_rate is : 0.094000004\n",
            "global_step is: 411 the epoch is  0 the num is: 410 the loss is : 0.7628627 the accuracy is : 0.734375 the learning_rate is : 0.094000004\n",
            "global_step is: 421 the epoch is  0 the num is: 420 the loss is : 0.9825046 the accuracy is : 0.46875 the learning_rate is : 0.094000004\n",
            "global_step is: 431 the epoch is  0 the num is: 430 the loss is : 0.7757484 the accuracy is : 0.765625 the learning_rate is : 0.094000004\n",
            "global_step is: 441 the epoch is  0 the num is: 440 the loss is : 0.79131925 the accuracy is : 0.609375 the learning_rate is : 0.094000004\n",
            "global_step is: 451 the epoch is  0 the num is: 450 the loss is : 0.5907742 the accuracy is : 0.71875 the learning_rate is : 0.094000004\n",
            "global_step is: 461 the epoch is  0 the num is: 460 the loss is : 0.5531561 the accuracy is : 0.734375 the learning_rate is : 0.094000004\n",
            "global_step is: 471 the epoch is  0 the num is: 470 the loss is : 0.9663509 the accuracy is : 0.5625 the learning_rate is : 0.094000004\n",
            "global_step is: 481 the epoch is  0 the num is: 480 the loss is : 0.48146987 the accuracy is : 0.78125 the learning_rate is : 0.094000004\n",
            "global_step is: 491 the epoch is  0 the num is: 490 the loss is : 0.5300147 the accuracy is : 0.78125 the learning_rate is : 0.094000004\n",
            "global_step is: 501 the epoch is  0 the num is: 500 the loss is : 0.8269144 the accuracy is : 0.625 the learning_rate is : 0.094000004\n",
            "global_step is: 511 the epoch is  0 the num is: 510 the loss is : 0.6741352 the accuracy is : 0.6875 the learning_rate is : 0.094000004\n",
            "global_step is: 521 the epoch is  0 the num is: 520 the loss is : 0.5245675 the accuracy is : 0.765625 the learning_rate is : 0.094000004\n",
            "global_step is: 531 the epoch is  0 the num is: 530 the loss is : 0.323803 the accuracy is : 0.828125 the learning_rate is : 0.094000004\n",
            "global_step is: 541 the epoch is  0 the num is: 540 the loss is : 0.23113225 the accuracy is : 0.890625 the learning_rate is : 0.094000004\n",
            "global_step is: 551 the epoch is  0 the num is: 550 the loss is : 0.17739926 the accuracy is : 0.921875 the learning_rate is : 0.094000004\n",
            "global_step is: 561 the epoch is  0 the num is: 560 the loss is : 0.1481233 the accuracy is : 0.96875 the learning_rate is : 0.094000004\n",
            "global_step is: 571 the epoch is  0 the num is: 570 the loss is : 2.8776126 the accuracy is : 0.3125 the learning_rate is : 0.094000004\n",
            "global_step is: 581 the epoch is  0 the num is: 580 the loss is : 1.3634567 the accuracy is : 0.390625 the learning_rate is : 0.094000004\n",
            "global_step is: 591 the epoch is  0 the num is: 590 the loss is : 1.3939884 the accuracy is : 0.421875 the learning_rate is : 0.094000004\n",
            "global_step is: 601 the epoch is  0 the num is: 600 the loss is : 1.3383555 the accuracy is : 0.421875 the learning_rate is : 0.088360004\n",
            "global_step is: 611 the epoch is  0 the num is: 610 the loss is : 1.1416097 the accuracy is : 0.421875 the learning_rate is : 0.088360004\n",
            "global_step is: 621 the epoch is  0 the num is: 620 the loss is : 0.956445 the accuracy is : 0.59375 the learning_rate is : 0.088360004\n",
            "global_step is: 631 the epoch is  0 the num is: 630 the loss is : 0.7924488 the accuracy is : 0.65625 the learning_rate is : 0.088360004\n",
            "global_step is: 641 the epoch is  0 the num is: 640 the loss is : 0.8777343 the accuracy is : 0.6875 the learning_rate is : 0.088360004\n",
            "global_step is: 651 the epoch is  0 the num is: 650 the loss is : 0.74622536 the accuracy is : 0.734375 the learning_rate is : 0.088360004\n",
            "global_step is: 661 the epoch is  0 the num is: 660 the loss is : 0.7396536 the accuracy is : 0.6875 the learning_rate is : 0.088360004\n",
            "global_step is: 671 the epoch is  0 the num is: 670 the loss is : 0.5758665 the accuracy is : 0.796875 the learning_rate is : 0.088360004\n",
            "global_step is: 681 the epoch is  0 the num is: 680 the loss is : 0.62887394 the accuracy is : 0.703125 the learning_rate is : 0.088360004\n",
            "global_step is: 691 the epoch is  0 the num is: 690 the loss is : 0.7661135 the accuracy is : 0.640625 the learning_rate is : 0.088360004\n",
            "global_step is: 701 the epoch is  0 the num is: 700 the loss is : 0.4350556 the accuracy is : 0.8125 the learning_rate is : 0.088360004\n",
            "global_step is: 711 the epoch is  0 the num is: 710 the loss is : 0.3254463 the accuracy is : 0.875 the learning_rate is : 0.088360004\n",
            "global_step is: 721 the epoch is  0 the num is: 720 the loss is : 0.52374035 the accuracy is : 0.734375 the learning_rate is : 0.088360004\n",
            "global_step is: 731 the epoch is  0 the num is: 730 the loss is : 0.3323977 the accuracy is : 0.875 the learning_rate is : 0.088360004\n",
            "global_step is: 741 the epoch is  0 the num is: 740 the loss is : 0.36126435 the accuracy is : 0.890625 the learning_rate is : 0.088360004\n",
            "global_step is: 751 the epoch is  0 the num is: 750 the loss is : 1.0312338 the accuracy is : 0.75 the learning_rate is : 0.088360004\n",
            "global_step is: 761 the epoch is  0 the num is: 760 the loss is : 0.93742883 the accuracy is : 0.515625 the learning_rate is : 0.088360004\n",
            "global_step is: 771 the epoch is  0 the num is: 770 the loss is : 0.8568332 the accuracy is : 0.71875 the learning_rate is : 0.088360004\n",
            "global_step is: 781 the epoch is  0 the num is: 780 the loss is : 0.8476218 the accuracy is : 0.640625 the learning_rate is : 0.088360004\n",
            "global_step is: 791 the epoch is  0 the num is: 790 the loss is : 0.6091374 the accuracy is : 0.796875 the learning_rate is : 0.088360004\n",
            "global_step is: 801 the epoch is  0 the num is: 800 the loss is : 0.36820787 the accuracy is : 0.859375 the learning_rate is : 0.088360004\n",
            "global_step is: 811 the epoch is  0 the num is: 810 the loss is : 0.35701007 the accuracy is : 0.828125 the learning_rate is : 0.088360004\n",
            "global_step is: 821 the epoch is  0 the num is: 820 the loss is : 0.3340695 the accuracy is : 0.859375 the learning_rate is : 0.088360004\n",
            "global_step is: 831 the epoch is  0 the num is: 830 the loss is : 0.7831407 the accuracy is : 0.71875 the learning_rate is : 0.088360004\n",
            "global_step is: 841 the epoch is  0 the num is: 840 the loss is : 0.72728324 the accuracy is : 0.71875 the learning_rate is : 0.088360004\n",
            "global_step is: 851 the epoch is  0 the num is: 850 the loss is : 0.37011462 the accuracy is : 0.84375 the learning_rate is : 0.088360004\n",
            "global_step is: 861 the epoch is  0 the num is: 860 the loss is : 0.16966423 the accuracy is : 0.9375 the learning_rate is : 0.088360004\n",
            "global_step is: 871 the epoch is  0 the num is: 870 the loss is : 0.15715483 the accuracy is : 0.96875 the learning_rate is : 0.088360004\n",
            "global_step is: 881 the epoch is  0 the num is: 880 the loss is : 0.046882845 the accuracy is : 1.0 the learning_rate is : 0.088360004\n",
            "global_step is: 891 the epoch is  0 the num is: 890 the loss is : 0.16699378 the accuracy is : 0.921875 the learning_rate is : 0.088360004\n",
            "global_step is: 901 the epoch is  0 the num is: 900 the loss is : 0.81189096 the accuracy is : 0.65625 the learning_rate is : 0.0830584\n",
            "global_step is: 911 the epoch is  0 the num is: 910 the loss is : 0.8231464 the accuracy is : 0.734375 the learning_rate is : 0.0830584\n",
            "global_step is: 921 the epoch is  0 the num is: 920 the loss is : 0.6617346 the accuracy is : 0.75 the learning_rate is : 0.0830584\n",
            "global_step is: 931 the epoch is  0 the num is: 930 the loss is : 0.4799679 the accuracy is : 0.8125 the learning_rate is : 0.0830584\n",
            "global_step is: 941 the epoch is  0 the num is: 940 the loss is : 0.35115603 the accuracy is : 0.890625 the learning_rate is : 0.0830584\n",
            "global_step is: 951 the epoch is  0 the num is: 950 the loss is : 0.30447245 the accuracy is : 0.875 the learning_rate is : 0.0830584\n",
            "global_step is: 961 the epoch is  0 the num is: 960 the loss is : 0.1941554 the accuracy is : 0.9375 the learning_rate is : 0.0830584\n",
            "global_step is: 971 the epoch is  0 the num is: 970 the loss is : 0.20895731 the accuracy is : 0.890625 the learning_rate is : 0.0830584\n",
            "global_step is: 981 the epoch is  0 the num is: 980 the loss is : 0.21515192 the accuracy is : 0.890625 the learning_rate is : 0.0830584\n",
            "global_step is: 991 the epoch is  0 the num is: 990 the loss is : 0.13720126 the accuracy is : 0.9375 the learning_rate is : 0.0830584\n",
            "global_step is: 1001 the epoch is  0 the num is: 1000 the loss is : 0.30369028 the accuracy is : 0.84375 the learning_rate is : 0.0830584\n",
            "global_step is: 1011 the epoch is  0 the num is: 1010 the loss is : 0.18102583 the accuracy is : 0.90625 the learning_rate is : 0.0830584\n",
            "global_step is: 1021 the epoch is  0 the num is: 1020 the loss is : 0.10708426 the accuracy is : 0.9375 the learning_rate is : 0.0830584\n",
            "global_step is: 1031 the epoch is  0 the num is: 1030 the loss is : 0.07476112 the accuracy is : 0.984375 the learning_rate is : 0.0830584\n",
            "global_step is: 1041 the epoch is  0 the num is: 1040 the loss is : 0.15991303 the accuracy is : 0.90625 the learning_rate is : 0.0830584\n",
            "global_step is: 1051 the epoch is  0 the num is: 1050 the loss is : 0.15936288 the accuracy is : 0.921875 the learning_rate is : 0.0830584\n",
            "global_step is: 1061 the epoch is  0 the num is: 1060 the loss is : 0.68683475 the accuracy is : 0.796875 the learning_rate is : 0.0830584\n",
            "global_step is: 1071 the epoch is  0 the num is: 1070 the loss is : 0.6517214 the accuracy is : 0.71875 the learning_rate is : 0.0830584\n",
            "global_step is: 1081 the epoch is  0 the num is: 1080 the loss is : 0.8287151 the accuracy is : 0.734375 the learning_rate is : 0.0830584\n",
            "global_step is: 1091 the epoch is  0 the num is: 1090 the loss is : 0.60799825 the accuracy is : 0.703125 the learning_rate is : 0.0830584\n",
            "global_step is: 1101 the epoch is  0 the num is: 1100 the loss is : 0.364699 the accuracy is : 0.890625 the learning_rate is : 0.0830584\n",
            "global_step is: 1111 the epoch is  0 the num is: 1110 the loss is : 0.22298631 the accuracy is : 0.890625 the learning_rate is : 0.0830584\n",
            "global_step is: 1121 the epoch is  0 the num is: 1120 the loss is : 0.32747555 the accuracy is : 0.890625 the learning_rate is : 0.0830584\n",
            "global_step is: 1131 the epoch is  0 the num is: 1130 the loss is : 0.17404039 the accuracy is : 0.921875 the learning_rate is : 0.0830584\n",
            "global_step is: 1141 the epoch is  0 the num is: 1140 the loss is : 0.11875127 the accuracy is : 0.90625 the learning_rate is : 0.0830584\n",
            "global_step is: 1151 the epoch is  0 the num is: 1150 the loss is : 0.05809595 the accuracy is : 1.0 the learning_rate is : 0.0830584\n",
            "global_step is: 1161 the epoch is  0 the num is: 1160 the loss is : 0.17252868 the accuracy is : 0.90625 the learning_rate is : 0.0830584\n",
            "global_step is: 1171 the epoch is  0 the num is: 1170 the loss is : 0.1972652 the accuracy is : 0.875 the learning_rate is : 0.0830584\n",
            "global_step is: 1181 the epoch is  0 the num is: 1180 the loss is : 0.07865998 the accuracy is : 0.984375 the learning_rate is : 0.0830584\n",
            "global_step is: 1191 the epoch is  0 the num is: 1190 the loss is : 0.17211124 the accuracy is : 0.953125 the learning_rate is : 0.0830584\n",
            "global_step is: 1201 the epoch is  0 the num is: 1200 the loss is : 0.0739615 the accuracy is : 0.96875 the learning_rate is : 0.078074895\n",
            "global_step is: 1211 the epoch is  0 the num is: 1210 the loss is : 0.13620214 the accuracy is : 0.9375 the learning_rate is : 0.078074895\n",
            "global_step is: 1221 the epoch is  0 the num is: 1220 the loss is : 1.4124272 the accuracy is : 0.71875 the learning_rate is : 0.078074895\n",
            "global_step is: 1231 the epoch is  0 the num is: 1230 the loss is : 0.68637496 the accuracy is : 0.75 the learning_rate is : 0.078074895\n",
            "global_step is: 1241 the epoch is  0 the num is: 1240 the loss is : 0.3046986 the accuracy is : 0.890625 the learning_rate is : 0.078074895\n",
            "global_step is: 1251 the epoch is  0 the num is: 1250 the loss is : 0.28217766 the accuracy is : 0.875 the learning_rate is : 0.078074895\n",
            "global_step is: 1261 the epoch is  0 the num is: 1260 the loss is : 0.1214646 the accuracy is : 0.984375 the learning_rate is : 0.078074895\n",
            "global_step is: 1271 the epoch is  0 the num is: 1270 the loss is : 0.08769344 the accuracy is : 0.96875 the learning_rate is : 0.078074895\n",
            "global_step is: 1281 the epoch is  0 the num is: 1280 the loss is : 0.07145973 the accuracy is : 0.96875 the learning_rate is : 0.078074895\n",
            "global_step is: 1291 the epoch is  0 the num is: 1290 the loss is : 0.047662377 the accuracy is : 0.984375 the learning_rate is : 0.078074895\n",
            "global_step is: 1301 the epoch is  0 the num is: 1300 the loss is : 0.07701053 the accuracy is : 0.953125 the learning_rate is : 0.078074895\n",
            "global_step is: 1311 the epoch is  0 the num is: 1310 the loss is : 0.115654975 the accuracy is : 0.9375 the learning_rate is : 0.078074895\n",
            "global_step is: 1321 the epoch is  0 the num is: 1320 the loss is : 0.047299188 the accuracy is : 0.96875 the learning_rate is : 0.078074895\n",
            "global_step is: 1331 the epoch is  0 the num is: 1330 the loss is : 0.08740327 the accuracy is : 0.96875 the learning_rate is : 0.078074895\n",
            "global_step is: 1341 the epoch is  0 the num is: 1340 the loss is : 0.033045337 the accuracy is : 0.984375 the learning_rate is : 0.078074895\n",
            "global_step is: 1351 the epoch is  0 the num is: 1350 the loss is : 0.06680636 the accuracy is : 0.953125 the learning_rate is : 0.078074895\n",
            "global_step is: 1361 the epoch is  0 the num is: 1360 the loss is : 0.12756382 the accuracy is : 0.953125 the learning_rate is : 0.078074895\n",
            "global_step is: 1371 the epoch is  0 the num is: 1370 the loss is : 0.27839473 the accuracy is : 0.84375 the learning_rate is : 0.078074895\n",
            "global_step is: 1381 the epoch is  0 the num is: 1380 the loss is : 0.20715879 the accuracy is : 0.890625 the learning_rate is : 0.078074895\n",
            "global_step is: 1391 the epoch is  0 the num is: 1390 the loss is : 0.17935942 the accuracy is : 0.921875 the learning_rate is : 0.078074895\n",
            "global_step is: 1401 the epoch is  0 the num is: 1400 the loss is : 0.15840149 the accuracy is : 0.953125 the learning_rate is : 0.078074895\n",
            "global_step is: 1411 the epoch is  0 the num is: 1410 the loss is : 0.1483113 the accuracy is : 0.921875 the learning_rate is : 0.078074895\n",
            "global_step is: 1421 the epoch is  0 the num is: 1420 the loss is : 0.12113087 the accuracy is : 0.9375 the learning_rate is : 0.078074895\n",
            "global_step is: 1431 the epoch is  0 the num is: 1430 the loss is : 0.20065588 the accuracy is : 0.890625 the learning_rate is : 0.078074895\n",
            "global_step is: 1441 the epoch is  0 the num is: 1440 the loss is : 0.1445556 the accuracy is : 0.921875 the learning_rate is : 0.078074895\n",
            "global_step is: 1451 the epoch is  0 the num is: 1450 the loss is : 0.1372793 the accuracy is : 0.9375 the learning_rate is : 0.078074895\n",
            "global_step is: 1461 the epoch is  0 the num is: 1460 the loss is : 0.038661763 the accuracy is : 0.984375 the learning_rate is : 0.078074895\n",
            "global_step is: 1471 the epoch is  0 the num is: 1470 the loss is : 0.033201903 the accuracy is : 0.984375 the learning_rate is : 0.078074895\n",
            "global_step is: 1481 the epoch is  0 the num is: 1480 the loss is : 0.0558101 the accuracy is : 0.953125 the learning_rate is : 0.078074895\n",
            "global_step is: 1491 the epoch is  0 the num is: 1490 the loss is : 0.06648202 the accuracy is : 0.96875 the learning_rate is : 0.078074895\n",
            "global_step is: 1501 the epoch is  0 the num is: 1500 the loss is : 0.06095136 the accuracy is : 1.0 the learning_rate is : 0.0733904\n",
            "global_step is: 1511 the epoch is  0 the num is: 1510 the loss is : 0.092802346 the accuracy is : 0.96875 the learning_rate is : 0.0733904\n",
            "global_step is: 1521 the epoch is  0 the num is: 1520 the loss is : 0.07595229 the accuracy is : 0.953125 the learning_rate is : 0.0733904\n",
            "global_step is: 1531 the epoch is  0 the num is: 1530 the loss is : 0.050465606 the accuracy is : 0.96875 the learning_rate is : 0.0733904\n",
            "global_step is: 1541 the epoch is  0 the num is: 1540 the loss is : 0.045802973 the accuracy is : 0.984375 the learning_rate is : 0.0733904\n",
            "global_step is: 1551 the epoch is  0 the num is: 1550 the loss is : 0.05779236 the accuracy is : 0.96875 the learning_rate is : 0.0733904\n",
            "global_step is: 1561 the epoch is  0 the num is: 1560 the loss is : 0.010834347 the accuracy is : 1.0 the learning_rate is : 0.0733904\n",
            "save, the average accuracy and loss is : 0.7494098111395646 0.6102215\n",
            "global_step is: 1573 the epoch is  1 the num is: 10 the loss is : 0.049417794 the accuracy is : 0.984375 the learning_rate is : 0.0733904\n",
            "global_step is: 1583 the epoch is  1 the num is: 20 the loss is : 0.04302061 the accuracy is : 0.984375 the learning_rate is : 0.0733904\n",
            "global_step is: 1593 the epoch is  1 the num is: 30 the loss is : 0.054051112 the accuracy is : 0.984375 the learning_rate is : 0.0733904\n",
            "global_step is: 1603 the epoch is  1 the num is: 40 the loss is : 0.016775023 the accuracy is : 1.0 the learning_rate is : 0.0733904\n",
            "global_step is: 1613 the epoch is  1 the num is: 50 the loss is : 0.027211633 the accuracy is : 1.0 the learning_rate is : 0.0733904\n",
            "global_step is: 1623 the epoch is  1 the num is: 60 the loss is : 0.06405566 the accuracy is : 0.953125 the learning_rate is : 0.0733904\n",
            "global_step is: 1633 the epoch is  1 the num is: 70 the loss is : 0.056569327 the accuracy is : 0.96875 the learning_rate is : 0.0733904\n",
            "global_step is: 1643 the epoch is  1 the num is: 80 the loss is : 0.046451822 the accuracy is : 0.984375 the learning_rate is : 0.0733904\n",
            "global_step is: 1653 the epoch is  1 the num is: 90 the loss is : 0.010645861 the accuracy is : 1.0 the learning_rate is : 0.0733904\n",
            "global_step is: 1663 the epoch is  1 the num is: 100 the loss is : 0.11109233 the accuracy is : 0.984375 the learning_rate is : 0.0733904\n",
            "global_step is: 1673 the epoch is  1 the num is: 110 the loss is : 13.027819 the accuracy is : 0.296875 the learning_rate is : 0.0733904\n",
            "global_step is: 1683 the epoch is  1 the num is: 120 the loss is : 2.5957022 the accuracy is : 0.28125 the learning_rate is : 0.0733904\n",
            "global_step is: 1693 the epoch is  1 the num is: 130 the loss is : 1.8925148 the accuracy is : 0.140625 the learning_rate is : 0.0733904\n",
            "global_step is: 1703 the epoch is  1 the num is: 140 the loss is : 1.9213552 the accuracy is : 0.203125 the learning_rate is : 0.0733904\n",
            "global_step is: 1713 the epoch is  1 the num is: 150 the loss is : 1.4659774 the accuracy is : 0.328125 the learning_rate is : 0.0733904\n",
            "global_step is: 1723 the epoch is  1 the num is: 160 the loss is : 1.3803909 the accuracy is : 0.34375 the learning_rate is : 0.0733904\n",
            "global_step is: 1733 the epoch is  1 the num is: 170 the loss is : 1.4428988 the accuracy is : 0.265625 the learning_rate is : 0.0733904\n",
            "global_step is: 1743 the epoch is  1 the num is: 180 the loss is : 1.4478413 the accuracy is : 0.296875 the learning_rate is : 0.0733904\n",
            "global_step is: 1753 the epoch is  1 the num is: 190 the loss is : 1.3941745 the accuracy is : 0.328125 the learning_rate is : 0.0733904\n",
            "global_step is: 1763 the epoch is  1 the num is: 200 the loss is : 1.3299286 the accuracy is : 0.375 the learning_rate is : 0.0733904\n",
            "global_step is: 1773 the epoch is  1 the num is: 210 the loss is : 1.4277568 the accuracy is : 0.359375 the learning_rate is : 0.0733904\n",
            "global_step is: 1783 the epoch is  1 the num is: 220 the loss is : 1.4487946 the accuracy is : 0.296875 the learning_rate is : 0.0733904\n",
            "global_step is: 1793 the epoch is  1 the num is: 230 the loss is : 1.3982615 the accuracy is : 0.265625 the learning_rate is : 0.0733904\n",
            "global_step is: 1803 the epoch is  1 the num is: 240 the loss is : 1.4245896 the accuracy is : 0.328125 the learning_rate is : 0.068986975\n",
            "global_step is: 1813 the epoch is  1 the num is: 250 the loss is : 1.3543786 the accuracy is : 0.390625 the learning_rate is : 0.068986975\n",
            "global_step is: 1823 the epoch is  1 the num is: 260 the loss is : 1.448118 the accuracy is : 0.296875 the learning_rate is : 0.068986975\n",
            "global_step is: 1833 the epoch is  1 the num is: 270 the loss is : 1.452224 the accuracy is : 0.265625 the learning_rate is : 0.068986975\n",
            "global_step is: 1843 the epoch is  1 the num is: 280 the loss is : 1.3106728 the accuracy is : 0.421875 the learning_rate is : 0.068986975\n",
            "global_step is: 1853 the epoch is  1 the num is: 290 the loss is : 1.2119713 the accuracy is : 0.484375 the learning_rate is : 0.068986975\n",
            "global_step is: 1863 the epoch is  1 the num is: 300 the loss is : 1.4104364 the accuracy is : 0.3125 the learning_rate is : 0.068986975\n",
            "global_step is: 1873 the epoch is  1 the num is: 310 the loss is : 1.3780677 the accuracy is : 0.25 the learning_rate is : 0.068986975\n",
            "global_step is: 1883 the epoch is  1 the num is: 320 the loss is : 1.3770794 the accuracy is : 0.328125 the learning_rate is : 0.068986975\n",
            "global_step is: 1893 the epoch is  1 the num is: 330 the loss is : 1.2883856 the accuracy is : 0.359375 the learning_rate is : 0.068986975\n",
            "global_step is: 1903 the epoch is  1 the num is: 340 the loss is : 1.3390312 the accuracy is : 0.390625 the learning_rate is : 0.068986975\n",
            "global_step is: 1913 the epoch is  1 the num is: 350 the loss is : 1.2662272 the accuracy is : 0.359375 the learning_rate is : 0.068986975\n",
            "global_step is: 1923 the epoch is  1 the num is: 360 the loss is : 1.3613427 the accuracy is : 0.234375 the learning_rate is : 0.068986975\n",
            "global_step is: 1933 the epoch is  1 the num is: 370 the loss is : 1.3594553 the accuracy is : 0.3125 the learning_rate is : 0.068986975\n",
            "global_step is: 1943 the epoch is  1 the num is: 380 the loss is : 1.18881 the accuracy is : 0.4375 the learning_rate is : 0.068986975\n",
            "global_step is: 1953 the epoch is  1 the num is: 390 the loss is : 1.1787331 the accuracy is : 0.390625 the learning_rate is : 0.068986975\n",
            "global_step is: 1963 the epoch is  1 the num is: 400 the loss is : 1.0217311 the accuracy is : 0.578125 the learning_rate is : 0.068986975\n",
            "global_step is: 1973 the epoch is  1 the num is: 410 the loss is : 1.2162355 the accuracy is : 0.421875 the learning_rate is : 0.068986975\n",
            "global_step is: 1983 the epoch is  1 the num is: 420 the loss is : 1.1123745 the accuracy is : 0.546875 the learning_rate is : 0.068986975\n",
            "global_step is: 1993 the epoch is  1 the num is: 430 the loss is : 1.0782862 the accuracy is : 0.59375 the learning_rate is : 0.068986975\n",
            "global_step is: 2003 the epoch is  1 the num is: 440 the loss is : 1.0099239 the accuracy is : 0.5 the learning_rate is : 0.068986975\n",
            "global_step is: 2013 the epoch is  1 the num is: 450 the loss is : 1.0758638 the accuracy is : 0.53125 the learning_rate is : 0.068986975\n",
            "global_step is: 2023 the epoch is  1 the num is: 460 the loss is : 0.8419911 the accuracy is : 0.578125 the learning_rate is : 0.068986975\n",
            "global_step is: 2033 the epoch is  1 the num is: 470 the loss is : 1.0359099 the accuracy is : 0.53125 the learning_rate is : 0.068986975\n",
            "global_step is: 2043 the epoch is  1 the num is: 480 the loss is : 0.8538522 the accuracy is : 0.609375 the learning_rate is : 0.068986975\n",
            "global_step is: 2053 the epoch is  1 the num is: 490 the loss is : 1.0229988 the accuracy is : 0.59375 the learning_rate is : 0.068986975\n",
            "global_step is: 2063 the epoch is  1 the num is: 500 the loss is : 0.7831991 the accuracy is : 0.671875 the learning_rate is : 0.068986975\n",
            "global_step is: 2073 the epoch is  1 the num is: 510 the loss is : 0.89660096 the accuracy is : 0.625 the learning_rate is : 0.068986975\n",
            "global_step is: 2083 the epoch is  1 the num is: 520 the loss is : 0.86988676 the accuracy is : 0.703125 the learning_rate is : 0.068986975\n",
            "global_step is: 2093 the epoch is  1 the num is: 530 the loss is : 0.7637284 the accuracy is : 0.71875 the learning_rate is : 0.068986975\n",
            "global_step is: 2103 the epoch is  1 the num is: 540 the loss is : 0.7373834 the accuracy is : 0.6875 the learning_rate is : 0.06484776\n",
            "global_step is: 2113 the epoch is  1 the num is: 550 the loss is : 0.8398007 the accuracy is : 0.65625 the learning_rate is : 0.06484776\n",
            "global_step is: 2123 the epoch is  1 the num is: 560 the loss is : 0.4190038 the accuracy is : 0.9375 the learning_rate is : 0.06484776\n",
            "global_step is: 2133 the epoch is  1 the num is: 570 the loss is : 0.59289914 the accuracy is : 0.75 the learning_rate is : 0.06484776\n",
            "global_step is: 2143 the epoch is  1 the num is: 580 the loss is : 0.657659 the accuracy is : 0.6875 the learning_rate is : 0.06484776\n",
            "global_step is: 2153 the epoch is  1 the num is: 590 the loss is : 0.58535516 the accuracy is : 0.75 the learning_rate is : 0.06484776\n",
            "global_step is: 2163 the epoch is  1 the num is: 600 the loss is : 0.45547742 the accuracy is : 0.890625 the learning_rate is : 0.06484776\n",
            "global_step is: 2173 the epoch is  1 the num is: 610 the loss is : 0.42360407 the accuracy is : 0.84375 the learning_rate is : 0.06484776\n",
            "global_step is: 2183 the epoch is  1 the num is: 620 the loss is : 0.2996198 the accuracy is : 0.84375 the learning_rate is : 0.06484776\n",
            "global_step is: 2193 the epoch is  1 the num is: 630 the loss is : 0.6120695 the accuracy is : 0.734375 the learning_rate is : 0.06484776\n",
            "global_step is: 2203 the epoch is  1 the num is: 640 the loss is : 0.28247398 the accuracy is : 0.875 the learning_rate is : 0.06484776\n",
            "global_step is: 2213 the epoch is  1 the num is: 650 the loss is : 0.24096686 the accuracy is : 0.9375 the learning_rate is : 0.06484776\n",
            "global_step is: 2223 the epoch is  1 the num is: 660 the loss is : 3.583786 the accuracy is : 0.4375 the learning_rate is : 0.06484776\n",
            "global_step is: 2233 the epoch is  1 the num is: 670 the loss is : 0.9635536 the accuracy is : 0.5 the learning_rate is : 0.06484776\n",
            "global_step is: 2243 the epoch is  1 the num is: 680 the loss is : 0.9595918 the accuracy is : 0.578125 the learning_rate is : 0.06484776\n",
            "global_step is: 2253 the epoch is  1 the num is: 690 the loss is : 1.410891 the accuracy is : 0.53125 the learning_rate is : 0.06484776\n",
            "global_step is: 2263 the epoch is  1 the num is: 700 the loss is : 1.0177746 the accuracy is : 0.578125 the learning_rate is : 0.06484776\n",
            "global_step is: 2273 the epoch is  1 the num is: 710 the loss is : 0.8964797 the accuracy is : 0.578125 the learning_rate is : 0.06484776\n",
            "global_step is: 2283 the epoch is  1 the num is: 720 the loss is : 0.9598298 the accuracy is : 0.578125 the learning_rate is : 0.06484776\n",
            "global_step is: 2293 the epoch is  1 the num is: 730 the loss is : 0.9165399 the accuracy is : 0.578125 the learning_rate is : 0.06484776\n",
            "global_step is: 2303 the epoch is  1 the num is: 740 the loss is : 0.987024 the accuracy is : 0.5625 the learning_rate is : 0.06484776\n",
            "global_step is: 2313 the epoch is  1 the num is: 750 the loss is : 0.9643189 the accuracy is : 0.59375 the learning_rate is : 0.06484776\n",
            "global_step is: 2323 the epoch is  1 the num is: 760 the loss is : 1.012202 the accuracy is : 0.53125 the learning_rate is : 0.06484776\n",
            "global_step is: 2333 the epoch is  1 the num is: 770 the loss is : 0.8941065 the accuracy is : 0.609375 the learning_rate is : 0.06484776\n",
            "global_step is: 2343 the epoch is  1 the num is: 780 the loss is : 0.764667 the accuracy is : 0.734375 the learning_rate is : 0.06484776\n",
            "global_step is: 2353 the epoch is  1 the num is: 790 the loss is : 0.7915848 the accuracy is : 0.578125 the learning_rate is : 0.06484776\n",
            "global_step is: 2363 the epoch is  1 the num is: 800 the loss is : 0.9333489 the accuracy is : 0.59375 the learning_rate is : 0.06484776\n",
            "global_step is: 2373 the epoch is  1 the num is: 810 the loss is : 0.77828395 the accuracy is : 0.640625 the learning_rate is : 0.06484776\n",
            "global_step is: 2383 the epoch is  1 the num is: 820 the loss is : 0.94195473 the accuracy is : 0.671875 the learning_rate is : 0.06484776\n",
            "global_step is: 2393 the epoch is  1 the num is: 830 the loss is : 0.8401686 the accuracy is : 0.65625 the learning_rate is : 0.06484776\n",
            "global_step is: 2403 the epoch is  1 the num is: 840 the loss is : 0.79519635 the accuracy is : 0.578125 the learning_rate is : 0.06095689\n",
            "global_step is: 2413 the epoch is  1 the num is: 850 the loss is : 0.9201831 the accuracy is : 0.6875 the learning_rate is : 0.06095689\n",
            "global_step is: 2423 the epoch is  1 the num is: 860 the loss is : 0.7378042 the accuracy is : 0.65625 the learning_rate is : 0.06095689\n",
            "global_step is: 2433 the epoch is  1 the num is: 870 the loss is : 0.74958766 the accuracy is : 0.640625 the learning_rate is : 0.06095689\n",
            "global_step is: 2443 the epoch is  1 the num is: 880 the loss is : 0.7004123 the accuracy is : 0.71875 the learning_rate is : 0.06095689\n",
            "global_step is: 2453 the epoch is  1 the num is: 890 the loss is : 0.80407643 the accuracy is : 0.609375 the learning_rate is : 0.06095689\n",
            "global_step is: 2463 the epoch is  1 the num is: 900 the loss is : 1.1721444 the accuracy is : 0.515625 the learning_rate is : 0.06095689\n",
            "global_step is: 2473 the epoch is  1 the num is: 910 the loss is : 0.9679451 the accuracy is : 0.546875 the learning_rate is : 0.06095689\n",
            "global_step is: 2483 the epoch is  1 the num is: 920 the loss is : 1.0958735 the accuracy is : 0.4375 the learning_rate is : 0.06095689\n",
            "global_step is: 2493 the epoch is  1 the num is: 930 the loss is : 1.0525922 the accuracy is : 0.546875 the learning_rate is : 0.06095689\n",
            "global_step is: 2503 the epoch is  1 the num is: 940 the loss is : 1.0427778 the accuracy is : 0.515625 the learning_rate is : 0.06095689\n",
            "global_step is: 2513 the epoch is  1 the num is: 950 the loss is : 0.77096957 the accuracy is : 0.640625 the learning_rate is : 0.06095689\n",
            "global_step is: 2523 the epoch is  1 the num is: 960 the loss is : 0.79493856 the accuracy is : 0.65625 the learning_rate is : 0.06095689\n",
            "global_step is: 2533 the epoch is  1 the num is: 970 the loss is : 0.8098566 the accuracy is : 0.59375 the learning_rate is : 0.06095689\n",
            "global_step is: 2543 the epoch is  1 the num is: 980 the loss is : 0.52849036 the accuracy is : 0.78125 the learning_rate is : 0.06095689\n",
            "global_step is: 2553 the epoch is  1 the num is: 990 the loss is : 0.9689403 the accuracy is : 0.703125 the learning_rate is : 0.06095689\n",
            "global_step is: 2563 the epoch is  1 the num is: 1000 the loss is : 0.6318748 the accuracy is : 0.71875 the learning_rate is : 0.06095689\n",
            "global_step is: 2573 the epoch is  1 the num is: 1010 the loss is : 0.4994323 the accuracy is : 0.765625 the learning_rate is : 0.06095689\n",
            "global_step is: 2583 the epoch is  1 the num is: 1020 the loss is : 0.60222024 the accuracy is : 0.765625 the learning_rate is : 0.06095689\n",
            "global_step is: 2593 the epoch is  1 the num is: 1030 the loss is : 0.52187335 the accuracy is : 0.75 the learning_rate is : 0.06095689\n",
            "global_step is: 2603 the epoch is  1 the num is: 1040 the loss is : 0.5296833 the accuracy is : 0.734375 the learning_rate is : 0.06095689\n",
            "global_step is: 2613 the epoch is  1 the num is: 1050 the loss is : 0.6151737 the accuracy is : 0.734375 the learning_rate is : 0.06095689\n",
            "global_step is: 2623 the epoch is  1 the num is: 1060 the loss is : 0.46287322 the accuracy is : 0.765625 the learning_rate is : 0.06095689\n",
            "global_step is: 2633 the epoch is  1 the num is: 1070 the loss is : 0.4559587 the accuracy is : 0.765625 the learning_rate is : 0.06095689\n",
            "global_step is: 2643 the epoch is  1 the num is: 1080 the loss is : 0.71515775 the accuracy is : 0.640625 the learning_rate is : 0.06095689\n",
            "global_step is: 2653 the epoch is  1 the num is: 1090 the loss is : 0.5673804 the accuracy is : 0.78125 the learning_rate is : 0.06095689\n",
            "global_step is: 2663 the epoch is  1 the num is: 1100 the loss is : 0.6048554 the accuracy is : 0.765625 the learning_rate is : 0.06095689\n",
            "global_step is: 2673 the epoch is  1 the num is: 1110 the loss is : 0.45705485 the accuracy is : 0.765625 the learning_rate is : 0.06095689\n",
            "global_step is: 2683 the epoch is  1 the num is: 1120 the loss is : 0.49776214 the accuracy is : 0.796875 the learning_rate is : 0.06095689\n",
            "global_step is: 2693 the epoch is  1 the num is: 1130 the loss is : 0.54601127 the accuracy is : 0.71875 the learning_rate is : 0.06095689\n",
            "global_step is: 2703 the epoch is  1 the num is: 1140 the loss is : 0.56098825 the accuracy is : 0.734375 the learning_rate is : 0.057299476\n",
            "global_step is: 2713 the epoch is  1 the num is: 1150 the loss is : 0.4393016 the accuracy is : 0.796875 the learning_rate is : 0.057299476\n",
            "global_step is: 2723 the epoch is  1 the num is: 1160 the loss is : 0.27849942 the accuracy is : 0.875 the learning_rate is : 0.057299476\n",
            "global_step is: 2733 the epoch is  1 the num is: 1170 the loss is : 0.2392037 the accuracy is : 0.890625 the learning_rate is : 0.057299476\n",
            "global_step is: 2743 the epoch is  1 the num is: 1180 the loss is : 0.44296548 the accuracy is : 0.828125 the learning_rate is : 0.057299476\n",
            "global_step is: 2753 the epoch is  1 the num is: 1190 the loss is : 0.48593622 the accuracy is : 0.78125 the learning_rate is : 0.057299476\n",
            "global_step is: 2763 the epoch is  1 the num is: 1200 the loss is : 0.53749293 the accuracy is : 0.75 the learning_rate is : 0.057299476\n",
            "global_step is: 2773 the epoch is  1 the num is: 1210 the loss is : 0.38966388 the accuracy is : 0.859375 the learning_rate is : 0.057299476\n",
            "global_step is: 2783 the epoch is  1 the num is: 1220 the loss is : 0.37832057 the accuracy is : 0.8125 the learning_rate is : 0.057299476\n",
            "global_step is: 2793 the epoch is  1 the num is: 1230 the loss is : 0.37413996 the accuracy is : 0.78125 the learning_rate is : 0.057299476\n",
            "global_step is: 2803 the epoch is  1 the num is: 1240 the loss is : 0.3824088 the accuracy is : 0.8125 the learning_rate is : 0.057299476\n",
            "global_step is: 2813 the epoch is  1 the num is: 1250 the loss is : 0.55000913 the accuracy is : 0.71875 the learning_rate is : 0.057299476\n",
            "global_step is: 2823 the epoch is  1 the num is: 1260 the loss is : 1.3753512 the accuracy is : 0.4375 the learning_rate is : 0.057299476\n",
            "global_step is: 2833 the epoch is  1 the num is: 1270 the loss is : 1.0715561 the accuracy is : 0.453125 the learning_rate is : 0.057299476\n",
            "global_step is: 2843 the epoch is  1 the num is: 1280 the loss is : 0.603105 the accuracy is : 0.734375 the learning_rate is : 0.057299476\n",
            "global_step is: 2853 the epoch is  1 the num is: 1290 the loss is : 0.9609132 the accuracy is : 0.671875 the learning_rate is : 0.057299476\n",
            "global_step is: 2863 the epoch is  1 the num is: 1300 the loss is : 0.42813277 the accuracy is : 0.796875 the learning_rate is : 0.057299476\n",
            "global_step is: 2873 the epoch is  1 the num is: 1310 the loss is : 0.48535073 the accuracy is : 0.78125 the learning_rate is : 0.057299476\n",
            "global_step is: 2883 the epoch is  1 the num is: 1320 the loss is : 0.37400353 the accuracy is : 0.859375 the learning_rate is : 0.057299476\n",
            "global_step is: 2893 the epoch is  1 the num is: 1330 the loss is : 0.4214889 the accuracy is : 0.765625 the learning_rate is : 0.057299476\n",
            "global_step is: 2903 the epoch is  1 the num is: 1340 the loss is : 0.571762 the accuracy is : 0.640625 the learning_rate is : 0.057299476\n",
            "global_step is: 2913 the epoch is  1 the num is: 1350 the loss is : 0.44828248 the accuracy is : 0.71875 the learning_rate is : 0.057299476\n",
            "global_step is: 2923 the epoch is  1 the num is: 1360 the loss is : 0.3488114 the accuracy is : 0.859375 the learning_rate is : 0.057299476\n",
            "global_step is: 2933 the epoch is  1 the num is: 1370 the loss is : 0.36813983 the accuracy is : 0.8125 the learning_rate is : 0.057299476\n",
            "global_step is: 2943 the epoch is  1 the num is: 1380 the loss is : 0.38339022 the accuracy is : 0.84375 the learning_rate is : 0.057299476\n",
            "global_step is: 2953 the epoch is  1 the num is: 1390 the loss is : 0.36141878 the accuracy is : 0.828125 the learning_rate is : 0.057299476\n",
            "global_step is: 2963 the epoch is  1 the num is: 1400 the loss is : 0.386812 the accuracy is : 0.859375 the learning_rate is : 0.057299476\n",
            "global_step is: 2973 the epoch is  1 the num is: 1410 the loss is : 0.30552083 the accuracy is : 0.890625 the learning_rate is : 0.057299476\n",
            "global_step is: 2983 the epoch is  1 the num is: 1420 the loss is : 0.28891137 the accuracy is : 0.921875 the learning_rate is : 0.057299476\n",
            "global_step is: 2993 the epoch is  1 the num is: 1430 the loss is : 0.34253 the accuracy is : 0.859375 the learning_rate is : 0.057299476\n",
            "global_step is: 3003 the epoch is  1 the num is: 1440 the loss is : 0.26837742 the accuracy is : 0.875 the learning_rate is : 0.05386151\n",
            "global_step is: 3013 the epoch is  1 the num is: 1450 the loss is : 0.259973 the accuracy is : 0.890625 the learning_rate is : 0.05386151\n",
            "global_step is: 3023 the epoch is  1 the num is: 1460 the loss is : 0.28690165 the accuracy is : 0.890625 the learning_rate is : 0.05386151\n",
            "global_step is: 3033 the epoch is  1 the num is: 1470 the loss is : 0.36491805 the accuracy is : 0.78125 the learning_rate is : 0.05386151\n",
            "global_step is: 3043 the epoch is  1 the num is: 1480 the loss is : 0.35566437 the accuracy is : 0.84375 the learning_rate is : 0.05386151\n",
            "global_step is: 3053 the epoch is  1 the num is: 1490 the loss is : 0.35114917 the accuracy is : 0.796875 the learning_rate is : 0.05386151\n",
            "global_step is: 3063 the epoch is  1 the num is: 1500 the loss is : 0.29293644 the accuracy is : 0.875 the learning_rate is : 0.05386151\n",
            "global_step is: 3073 the epoch is  1 the num is: 1510 the loss is : 0.48808178 the accuracy is : 0.796875 the learning_rate is : 0.05386151\n",
            "global_step is: 3083 the epoch is  1 the num is: 1520 the loss is : 0.41250324 the accuracy is : 0.78125 the learning_rate is : 0.05386151\n",
            "global_step is: 3093 the epoch is  1 the num is: 1530 the loss is : 0.42086825 the accuracy is : 0.796875 the learning_rate is : 0.05386151\n",
            "global_step is: 3103 the epoch is  1 the num is: 1540 the loss is : 0.36416513 the accuracy is : 0.828125 the learning_rate is : 0.05386151\n",
            "global_step is: 3113 the epoch is  1 the num is: 1550 the loss is : 0.25982404 the accuracy is : 0.90625 the learning_rate is : 0.05386151\n",
            "global_step is: 3123 the epoch is  1 the num is: 1560 the loss is : 0.28052402 the accuracy is : 0.90625 the learning_rate is : 0.05386151\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "save, the average accuracy and loss is : 0.6486575704225352 0.8881501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPpYh4FDxn0g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f5e5a621-ec0d-4246-eac7-b328df500fd5"
      },
      "source": [
        "! python test.py"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From test.py:10: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/inception_resnet_v2.py:241: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "Tensor(\"InceptionResnetV2/Logits/Logits/BiasAdd:0\", shape=(?, 200), dtype=float32)\n",
            "412 10 412 3 0\n",
            "WARNING:tensorflow:From test.py:16: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "1\n",
            "WARNING:tensorflow:From test.py:18: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-09-11 10:12:38.610462: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-09-11 10:12:38.630036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-11 10:12:38.630998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-11 10:12:38.631287: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-11 10:12:38.632826: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-11 10:12:38.634701: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-11 10:12:38.635075: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-11 10:12:38.637092: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-11 10:12:38.638531: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-11 10:12:38.643138: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-11 10:12:38.643264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-11 10:12:38.644169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-11 10:12:38.644908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-11 10:12:38.651104: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-09-11 10:12:38.651329: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b76bc0 executing computations on platform Host. Devices:\n",
            "2019-09-11 10:12:38.651364: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-09-11 10:12:38.717924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-11 10:12:38.718836: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b76a00 executing computations on platform CUDA. Devices:\n",
            "2019-09-11 10:12:38.718863: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-09-11 10:12:38.719068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-11 10:12:38.719767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-11 10:12:38.719868: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-11 10:12:38.719918: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-11 10:12:38.719963: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-11 10:12:38.720004: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-11 10:12:38.720043: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-11 10:12:38.720081: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-11 10:12:38.720121: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-11 10:12:38.720246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-11 10:12:38.721032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-11 10:12:38.721724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-11 10:12:38.721800: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-11 10:12:38.723505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-09-11 10:12:38.723550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-09-11 10:12:38.723568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-09-11 10:12:38.723797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-11 10:12:38.724597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-11 10:12:38.725384: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-09-11 10:12:38.725451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From test.py:19: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Traceback (most recent call last):\n",
            "  File \"test.py\", line 31, in <module>\n",
            "    result, tes = test()\n",
            "  File \"test.py\", line 24, in test\n",
            "    data = [cv2.resize(cv2.imread(i), (IMAGE_HEIGHT,IMAGE_WIDTH)) for i in test_data[num]]\n",
            "  File \"test.py\", line 24, in <listcomp>\n",
            "    data = [cv2.resize(cv2.imread(i), (IMAGE_HEIGHT,IMAGE_WIDTH)) for i in test_data[num]]\n",
            "cv2.error: OpenCV(3.4.3) /io/opencv/modules/imgproc/src/resize.cpp:4044: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_r8Rxu10_TC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P-H6Lw1vyNNd"
      },
      "source": [
        "## 机器学习示例：Seedbank\n",
        "\n",
        "要查看 Colaboratory 实现的互动机器学习分析的端到端示例，请查看 <a href=\"https://research.google.com/seedbank/\">Seedbank</a> 项目。\n",
        "\n",
        "一些精选示例：\n",
        "\n",
        "- <a href=\"https://research.google.com/seedbank/seed/neural_style_transfer_with_tfkeras\">神经风格迁移</a>：使用深度学习在图像之间迁移风格。\n",
        "- <a href=\"https://research.google.com/seedbank/seed/ez_nsynth\">EZ NSynth</a>：使用 WaveNet 自动编码器合成音频。\n",
        "- <a href=\"https://research.google.com/seedbank/seed/fashion_mnist_with_keras_and_tpus\">Fashion MNIST 与 Keras 和 TPU</a>：使用深度学习对时装图像进行分类。\n",
        "- <a href=\"https://research.google.com/seedbank/seed/deepdream\">DeepDream</a>：根据您自己的照片生成 DeepDream 图像。\n",
        "- <a href=\"https://research.google.com/seedbank/seed/convolutional_vae\">卷积 VAE</a>：创建手写数字生成模型。"
      ]
    }
  ]
}